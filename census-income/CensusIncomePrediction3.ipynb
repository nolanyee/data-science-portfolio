{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income Class Prediction from Census Data\n",
    "\n",
    "## Subsampling and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(lattice)\n",
    "library(stringr)\n",
    "library(gridExtra)\n",
    "library(caret)\n",
    "library(rpart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes in the data set are very imbalanced. The low income class has ~15 times more samples than the high income class. Therefore the low income class will be subsampled. The set of samples with low income will be divided randomly into 15. Each of the subsamples will be combined with the complete high income class data and modeled. Then the 15 models will be ensembled.\n",
    "\n",
    "First import the complete data after imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- read.csv('C:/Datasets/censusincomedfFull.csv')$income\n",
    "X <- read.csv('C:/Datasets/censusincomeXFull.csv')\n",
    "X <- as.matrix(X[,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All samples are randomly assigned a number between 1 and 15, using the following vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetnumber <- floor(runif(length(y),1,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "Different models will be explored with the first subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 <- y[(y==' 50000+.')|(subsetnumber==1)]\n",
    "X1 <- X[(y==' 50000+.')|(subsetnumber==1),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nature of the data is such that the relevance of many features is dependent on the levels of other features. Some levels of some features will always be associated with 'Not in universe' for other features. In other words, not all combinations of levels of features is possible. Therefore tree models are more appropriate for the data than models based on n-dimensional spaces (kNN, SVM, LDA etc.). Tree models do not require the scaling of variables.\n",
    "\n",
    "Due to the large size of the data sets, a simple decision tree model will be used instead of random forest or boosted trees. Cross validation will be used to optimize the complexity parameter to avoid overfitting. Variance will be further reduced when all 15 models are ensembled at the end. Model tuning will be performed on the first subset of the data, and the resulting complexity parameter will be applied to the other subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "24680 samples\n",
       "  470 predictor\n",
       "    2 classes: ' - 50000.', ' 50000+.' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 3 times) \n",
       "Summary of sample sizes: 19745, 19743, 19744, 19745, 19743, 19744, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp          Accuracy   Kappa    \n",
       "  0.01784843  0.8010539  0.6019296\n",
       "  0.05773296  0.7821583  0.5639969\n",
       "  0.52764677  0.6587318  0.3158086\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01784843."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tree1 <- train(X1,y1,method ='rpart',trControl=trainControl(method='repeatedcv',number=5,repeats=3))\n",
    "Tree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "24556 samples\n",
       "  470 predictor\n",
       "    2 classes: ' - 50000.', ' 50000+.' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 3 times) \n",
       "Summary of sample sizes: 19645, 19644, 19645, 19645, 19645, 19645, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  0.010  0.8177903  0.6351486\n",
       "  0.012  0.8150483  0.6297254\n",
       "  0.014  0.8115461  0.6228002\n",
       "  0.016  0.8085190  0.6167348\n",
       "  0.018  0.8063065  0.6123177\n",
       "  0.020  0.7931662  0.5858328\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Grid <- expand.grid(cp=c(0.01,0.012,0.014,0.016,0.018,0.02))\n",
    "Tree1 <- train(X1,y1,method ='rpart',tuneGrid=Grid,trControl=trainControl(method='repeatedcv',number=5,repeats=3))\n",
    "Tree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "24556 samples\n",
       "  470 predictor\n",
       "    2 classes: ' - 50000.', ' 50000+.' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 3 times) \n",
       "Summary of sample sizes: 19645, 19646, 19644, 19644, 19645, 19645, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  0.002  0.8397404  0.6791669\n",
       "  0.004  0.8339711  0.6676271\n",
       "  0.006  0.8268989  0.6534380\n",
       "  0.008  0.8198271  0.6392343\n",
       "  0.010  0.8165964  0.6327686\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.002."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Grid <- expand.grid(cp=c(0.002,0.004,0.006,0.008, 0.01))\n",
    "Tree1 <- train(X1,y1,method ='rpart',tuneGrid=Grid,trControl=trainControl(method='repeatedcv',number=5,repeats=3))\n",
    "Tree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "24556 samples\n",
       "  470 predictor\n",
       "    2 classes: ' - 50000.', ' 50000+.' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 3 times) \n",
       "Summary of sample sizes: 19646, 19645, 19644, 19645, 19644, 19646, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  2e-04  0.8533558  0.7065983\n",
       "  4e-04  0.8541161  0.7080684\n",
       "  6e-04  0.8528537  0.7055255\n",
       "  8e-04  0.8503967  0.7006144\n",
       "  1e-03  0.8485369  0.6968867\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 4e-04."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Grid <- expand.grid(cp=c(0.0002,0.0004,0.0006,0.0008, 0.001))\n",
    "Tree1 <- train(X1,y1,method ='rpart',tuneGrid=Grid,trControl=trainControl(method='repeatedcv',number=5,repeats=3))\n",
    "Tree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "24556 samples\n",
       "  470 predictor\n",
       "    2 classes: ' - 50000.', ' 50000+.' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 3 times) \n",
       "Summary of sample sizes: 19645, 19646, 19645, 19644, 19644, 19644, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  2e-04  0.8509259  0.7017316\n",
       "  3e-04  0.8541297  0.7081031\n",
       "  4e-04  0.8546048  0.7090343\n",
       "  5e-04  0.8538581  0.7075450\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 4e-04."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Grid <- expand.grid(cp=c(0.0002,0.0003,0.0004,0.0005))\n",
    "Tree1 <- train(X1,y1,method ='rpart',tuneGrid=Grid,trControl=trainControl(method='repeatedcv',number=5,repeats=3))\n",
    "Tree1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity parameter value of 0.0004 will be used to build the models.\n",
    "\n",
    "## Model Fitting\n",
    "\n",
    "The remaining 14 models are fit below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 2:15){\n",
    "    Xtemp <- as.data.frame(X[(y==' 50000+.')|(subsetnumber==i),])\n",
    "    Xtemp$y <-y[(y==' 50000+.')|(subsetnumber==i)]\n",
    "    assign(paste('Tree',i,sep=''),rpart(y~.,Xtemp,cp=0.0004))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Ensembling\n",
    "\n",
    "Below is a function that will generate the ensembled prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemblepredict <- function(predictors){\n",
    "    for(i in 1:15){\n",
    "        if(i==1){\n",
    "            ypred <- as.data.frame(predict(get(paste('Tree',i,sep='')),predictors))\n",
    "            names(ypred)=c('y1')\n",
    "        }\n",
    "        else{\n",
    "            ypred[,paste('y',i,sep='')] <- predict(get(paste('Tree',i,sep='')),predictors,type='class')\n",
    "        } \n",
    "    }\n",
    "    return(ypred)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>y1</th><th scope=col>y2</th><th scope=col>y3</th><th scope=col>y4</th><th scope=col>y5</th><th scope=col>y6</th><th scope=col>y7</th><th scope=col>y8</th><th scope=col>y9</th><th scope=col>y10</th><th scope=col>y11</th><th scope=col>y12</th><th scope=col>y13</th><th scope=col>y14</th><th scope=col>y15</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td></tr>\n",
       "\t<tr><td> 50000+. </td><td> 50000+. </td><td> - 50000.</td><td> - 50000.</td><td> 50000+. </td><td> - 50000.</td><td> 50000+. </td><td> 50000+. </td><td> - 50000.</td><td> 50000+. </td><td> - 50000.</td><td> 50000+. </td><td> 50000+. </td><td> - 50000.</td><td> 50000+. </td></tr>\n",
       "\t<tr><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td></tr>\n",
       "\t<tr><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td></tr>\n",
       "\t<tr><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td><td> - 50000.</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " y1 & y2 & y3 & y4 & y5 & y6 & y7 & y8 & y9 & y10 & y11 & y12 & y13 & y14 & y15\\\\\n",
       "\\hline\n",
       "\t  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000.\\\\\n",
       "\t  50000+.  &  50000+.  &  - 50000. &  - 50000. &  50000+.  &  - 50000. &  50000+.  &  50000+.  &  - 50000. &  50000+.  &  - 50000. &  50000+.  &  50000+.  &  - 50000. &  50000+. \\\\\n",
       "\t  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000.\\\\\n",
       "\t  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000.\\\\\n",
       "\t  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000. &  - 50000.\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "y1 | y2 | y3 | y4 | y5 | y6 | y7 | y8 | y9 | y10 | y11 | y12 | y13 | y14 | y15 | \n",
       "|---|---|---|---|---|\n",
       "|  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. | \n",
       "|  50000+.  |  50000+.  |  - 50000. |  - 50000. |  50000+.  |  - 50000. |  50000+.  |  50000+.  |  - 50000. |  50000+.  |  - 50000. |  50000+.  |  50000+.  |  - 50000. |  50000+.  | \n",
       "|  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. | \n",
       "|  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. | \n",
       "|  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. |  - 50000. | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  y1        y2        y3        y4        y5        y6        y7       \n",
       "1  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "2  50000+.   50000+.   - 50000.  - 50000.  50000+.   - 50000.  50000+. \n",
       "3  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "4  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "5  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "  y8        y9        y10       y11       y12       y13       y14      \n",
       "1  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "2  50000+.   - 50000.  50000+.   - 50000.  50000+.   50000+.   - 50000.\n",
       "3  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "4  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "5  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.  - 50000.\n",
       "  y15      \n",
       "1  - 50000.\n",
       "2  50000+. \n",
       "3  - 50000.\n",
       "4  - 50000.\n",
       "5  - 50000."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yfullpred <- ensemblepredict(as.data.frame(X))\n",
    "head(yfullpred,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority class from the 15 predictions is taken as the final prediction. The results are summarized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "           Reference\n",
       "Prediction   - 50000.  50000+.\n",
       "   - 50000.    152152     1295\n",
       "   50000+.      31760    11087\n",
       "                                          \n",
       "               Accuracy : 0.8316          \n",
       "                 95% CI : (0.8299, 0.8333)\n",
       "    No Information Rate : 0.9369          \n",
       "    P-Value [Acc > NIR] : 1               \n",
       "                                          \n",
       "                  Kappa : 0.3366          \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 0.89541         \n",
       "            Specificity : 0.82731         \n",
       "         Pos Pred Value : 0.25876         \n",
       "         Neg Pred Value : 0.99156         \n",
       "             Prevalence : 0.06308         \n",
       "         Detection Rate : 0.05648         \n",
       "   Detection Prevalence : 0.21828         \n",
       "      Balanced Accuracy : 0.86136         \n",
       "                                          \n",
       "       'Positive' Class :  50000+.        \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred <- factor(apply(yfullpred,1,function(x){x[which.max(table(x))]}))\n",
    "confusionMatrix(ypred, y, positive =' 50000+.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is able to predict most of each class correctly, however it over predicts the positive class by a factor of 3, which results in very low precision. This is mainly due to the imbalance in the data. Since there are so many more instances of the negative class, even a small percentage of them that are misclassified is a large in comparison to the number of instances of the positive class. This likely would not have been as extreme if the data were not subsampled to balance the classes during model fitting. However, leaving the classes unbalanced would have resulted in under prediction of the positive class. We see that the balanced accuracy is higher than the accuracy value, indicating that the model would perform better on a balanced data set. \n",
    "\n",
    "Aside from the impact of imbalance, the high proportion of false positives could also be due to the fact that there may be other features not in the data set that contribute to a person's income. Success may depend highly on chance and personality in addition to the background/demographics of a person. Therefore only a minority of people with a certain background that is most associated with success may actually be able to acheive the high income."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
